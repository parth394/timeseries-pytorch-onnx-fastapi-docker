{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "import seaborn as sns\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "## Settings\n",
    "plt.rcParams['figure.figsize'] = [20, 7]\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Electricity_production.csv\")\n",
    "# df.index.freq = 'MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .assign(date=lambda x: pd.to_datetime(x[\"DATE\"]))\n",
    "    .assign(month=lambda x: x[\"date\"].dt.month,\n",
    "            year=lambda x: x[\"date\"].dt.year)\n",
    "    .set_index(\"date\")\n",
    "    .drop(\"DATE\", axis=1)\n",
    "    .rename(columns={\"IPG2211A2N\":\"production\"})\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=\"production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seasonal_decompose(df['production'])\n",
    "results.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(df['production'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df['production'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df['production'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = 100\n",
    "train_indices = df.shape[0]- test_indices\n",
    "train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df['production'].values[:train_indices]\n",
    "val = df['production'].values[train_indices:train_indices+50]\n",
    "test = df['production'].values[train_indices+50:]\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = scaler.transform(train.reshape(-1, 1))\n",
    "val = scaler.transform(val.reshape(-1, 1))\n",
    "test = scaler.transform(test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create sequence data\n",
    "# def create_sequence(input_data, sequence_length):\n",
    "#     sequences = []\n",
    "#     data_size = len(input_data)\n",
    "#     for i in range(data_size - sequence_length):\n",
    "#         features = input_data[i: i + sequence_length]\n",
    "#         target = input_data[i + sequence_length]\n",
    "#         sequences.append((th.Tensor(features), th.Tensor(target)))\n",
    "#     return sequences\n",
    "\n",
    "# sequence_length = 6\n",
    "# train_sequences = create_sequence(train, sequence_length)\n",
    "# test_sequences = create_sequence(test, sequence_length)\n",
    "# (len(train_sequences), len(test_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Dataset and DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x: np.ndarray , sequence_length: int, device: str=\"cpu\"):\n",
    "        self.x = x\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device=device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) - (self.sequence_length)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (th.Tensor(self.x[idx: idx+self.sequence_length]), th.Tensor(self.x[idx+self.sequence_length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityDataModule(L.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 train_sequences: np.ndarray, \n",
    "                 test_sequences:np.ndarray, \n",
    "                 val_sequences: np.ndarray,\n",
    "                 sequence_length: int, \n",
    "                 batch_size: int=10):\n",
    "        super().__init__()\n",
    "        self.train_sequences    =   train_sequences\n",
    "        self.test_sequences     =   test_sequences\n",
    "        self.val_sequences      =   val_sequences\n",
    "        self.sequence_length    =   sequence_length\n",
    "        self.batch_size         =   batch_size\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset  =   TimeSeriesDataset(self.train_sequences, self.sequence_length)\n",
    "        self.val_dataset    =   TimeSeriesDataset(self.val_sequences, self.sequence_length)\n",
    "        self.test_dataset   =   TimeSeriesDataset(self.test_sequences, self.sequence_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LSTM model\n",
    "class LSTMModel(L.LightningModule):\n",
    "    def __init__(self, n_features, n_hidden=128, n_layers=2, lr=1e-3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lstm = th.nn.LSTM(input_size = n_features, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "        self.output_layer = th.nn.Linear(n_hidden, 1)\n",
    "        self.layer_norm = th.nn.LayerNorm(n_hidden)\n",
    "        self.loss = th.nn.MSELoss()\n",
    "        self.learning_rate = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        # self.lstm.flatten_parameters()\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out_ = self.layer_norm(lstm_out[:, -1])\n",
    "        output = self.output_layer(lstm_out_)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # print(x.shape)\n",
    "        output = self(x)\n",
    "        loss = F.mse_loss(output, y)\n",
    "        self.log(f\"train_loss\", loss, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        test_loss = F.mse_loss(x_hat, y)\n",
    "        self.log(\"test_loss\", test_loss, logger=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        test_loss = F.mse_loss(x_hat, y)\n",
    "        self.log(\"validation_loss\", test_loss, logger=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimiser = th.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEST TRAINING PARAMS\n",
    "N_EPOCHS = 500\n",
    "BATCH_SIZE = 8\n",
    "SEQUENCE_LENGTH = 5\n",
    "N_HIDDEN = 32\n",
    "N_LAYERS = 1\n",
    "LR=1e-4\n",
    "\n",
    "# N_EPOCHS = 500\n",
    "# BATCH_SIZE = 8\n",
    "# SEQUENCE_LENGTH = 6\n",
    "# N_HIDDEN = 32\n",
    "# N_LAYERS = 1\n",
    "# LR=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ElectricityDataModule(train_sequences=train, test_sequences=test,val_sequences=val, sequence_length=SEQUENCE_LENGTH, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(n_features=1, n_hidden=N_HIDDEN, n_layers=N_LAYERS, lr=LR)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpont\",\n",
    "    save_top_k=1,\n",
    "    # verbose=True,\n",
    "    monitor=\"validation_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "logger = L.pytorch.loggers.tensorboard.TensorBoardLogger(\n",
    "    \"lightning_logs\",\n",
    "    name=\"electricity-prediction\"\n",
    ")\n",
    "\n",
    "early_stopping_callbacks = L.pytorch.callbacks.EarlyStopping(\n",
    "    monitor=\"train_loss\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[early_stopping_callbacks, checkpoint_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    # enable_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model=model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.predict(model=model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for temp in prediction:\n",
    "    final.extend(temp.reshape(1, -1).squeeze(0).tolist())\n",
    "final_scaled_prediction = scaler.inverse_transform(np.fromiter(final, dtype=np.float32).reshape(-1, 1))\n",
    "\n",
    "# scaler.inverse_transform(test).shape\n",
    "actual_final = []\n",
    "for ele in data_module.predict_dataloader():\n",
    "    actual_final.extend(ele[1].squeeze(1).tolist())\n",
    "\n",
    "actual_final = np.fromiter(actual_final, dtype=np.float32)\n",
    "actual_final = scaler.inverse_transform(actual_final.reshape(-1, 1))\n",
    "actual_final = actual_final.squeeze(1).tolist()\n",
    "final_scaled_prediction = final_scaled_prediction.squeeze(1).tolist()\n",
    "temp = pd.DataFrame(zip(actual_final, final_scaled_prediction), columns=[\"test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1)\n",
    "sns.lineplot( data=temp, y=\"test\", x=temp.index, ax=ax, label=\"Actual\")\n",
    "sns.scatterplot( data=temp, y=\"test\", x=temp.index, ax=ax)\n",
    "sns.lineplot( data=temp, y=\"y_pred\", x=temp.index, ax=ax, label=\"Predicted\")\n",
    "sns.scatterplot( data=temp, y=\"y_pred\", x=temp.index, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "onnx_program = th.onnx.export(\n",
    "    model, \n",
    "    th.zeros(1, 5, 1),\n",
    "    \"../data/TimeSeries_LSTM.onnx\",\n",
    "    export_params=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text][def]\n",
    "\n",
    "[def]: ../data/TimeSeries_LSTM.onnx.png \"Title1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
